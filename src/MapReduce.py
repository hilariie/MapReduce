"""Functions for reading data and performing MapReduce to identify a word with the highest occurrence or count"""
import os
import re
from operator import itemgetter
import pandas as pd
from concurrent.futures import ThreadPoolExecutor


class MapReduce:
    """MapReduce class for performing map and reduce operations on input data."""

    def __init__(self, pattern: list):
        """
        Initialize MapReduce object.

        Args:
            pattern (list): list of regular expression patterns used to check IDs
        """
        self.pattern = pattern

    def mapper1(self, id_: str, id_2: str) -> str:
        """
        Filters out rows with wrong flight IDs

        Args:
            id_: Passenger ID to be returned or not
            id_2: Flight ID to be checked if it matches given pattern

        Returns:
            str: Returns Passenger ID if Flight ID matches pattern, otherwise return empty string
        """
        if re.findall(self.pattern[1], id_2):
            return id_
        else:
            return ''

    def mapper2(self, id_, count_=1) -> tuple:
        """
        Checks if passenger ID matches given pattern and returns a key-value pair

        Args:
            id_ (str): Passenger ID to be returned as key
            count_ (int): Second input to be returned as value. Default is 1.
        Returns:
            tuple: A tuple containing the passenger id and a count if passenger id matches pattern,
                   otherwise return a tuple of passenger id and None-type object
        """
        id_ = str(id_)
        try:
            int(count_)
        except ValueError:
            count_ = None
        except TypeError:
            count_ = None
        if re.findall(self.pattern[0], id_):
            return id_, count_
        else:
            return id_, None

    @staticmethod
    def shuffle(mapper_out: list) -> dict:
        """Joins the counts of each id in a list and store data as dict
        Args:
            mapper_out: List of key-value pairs generated by the mapper method.

        Returns:
            dict: A dictionary containing the organized key-value pairs.
        """
        data = {}

        # loop through key-value pair
        for id_, count_ in mapper_out:
            # check if count is int or a Nonetype object
            try:
                int(count_)
            except TypeError:
                continue  # Silently discard id which doesn't match pattern
            # if new id encountered, store id in dictionary as key and count as value
            # else append the count to the id being the key
            if id_ not in data:
                data[id_] = [count_]
            else:
                data[id_].append(count_)
        return data  # of shape -> {'id1': [1, 1, 1], 'id2': [1, 1]}

    @staticmethod
    def reduce_func(x: int, y: int) -> int:
        """Reduce function to process values for the same key.

        Args:
            x (int): First value to be reduced.
            y (int): Second value to be reduced.
        Returns:
            int: sum of provided integers
        """
        return x + y

    @staticmethod
    def final_output(reduce_out: dict, test=False) -> tuple:
        """
        Get the passenger id(s) with the highest number of flights.

        Args:
            reduce_out (dict): Dictionary of reduced key-value pairs.
            test (bool): bool value used solely for testing.

        Returns:
            tuple: count and word pair for word(s) with the highest number of occurences or counts
        """
        # if test is True, input dict will not have future object as values, so we skip processing of extracting results
        # from future objects
        if test:
            sorted_items = reduce_out
        else:
            # Retrieve results using ThreadPoolExecutor.map()
            with ThreadPoolExecutor() as executor:
                sorted_items = list(executor.map(lambda item: (item[0], item[1].result()), reduce_out.items()))
        # convert list of tuples to dictionary
        sorted_items = dict(sorted_items)
        # get maximum occurence of any word(ID) in dictionary
        max_count = max(sorted_items.values())
        # get all IDs with maximum occurence
        passengers = [pass_id for pass_id, value in list(sorted_items.items()) if value == max_count]
        # sort and convert list of IDs to formatted strings for pleasant display
        passengers = '\n\t '.join(sorted(passengers))
        return max_count, passengers


def pretty_print(string1, string2=None, count_=7):
    """
    Print formatted strings with optional second string.
    Args:
        string1 (str): The first string to be printed.
        string2 (str, optional): The second string to be printed. Default is None.
        count_ (int, optional): The number of '-' characters for formatting. Default is 7.
    """
    print_style = '-' * count_
    if not string2:
        print(f"{print_style} {string1}:  {print_style}")
    else:
        print(f"{print_style} {string1}:  {print_style}\n\n{string2}")


def header_reader(header):
    """
    Checks if dataset has headers or not based on input

    Args:
        header: Indicator if dataset has headers or not

    Returns:
        returns 0 ('infer') if dataset has headers, otherwise None
    """
    if header:
        return 0
    else:
        return None


def read_data(path, column_ind, sum_col=False, header=None, chunk_size=1000) -> tuple:
    """
    Reads a CSV file and returns a tuple of needed column data.

    Args:
        path (str): Path to CSV file containing the data.
        sum_col (int): Index of column to be summed by reducer. Default is False.
        column_ind (list): list containing index of needed column(s) data.
        header (int): Indicates if csv file has headers or not. Defaults to None.
        chunk_size (int): Number of chunks to read csv file.

    Returns:
        tuple: Tuple of needed column data

    Raises:
        FileNotFoundError: If the CSV file does not exist.
        ValueError: If column_ind list has wrong length
    """
    # check if path exists otherwise throw error with efficient error message
    path_ext = os.path.splitext(path)
    if not os.path.exists(path):
        raise FileNotFoundError(f"Path to file not found: {path}")
    # check if file is a csv file
    elif path_ext[1] != '.csv':
        raise FileNotFoundError(f'Expected .csv file, got {path_ext[1]} instead')
    header = header_reader(header)
    # use iterator to handle large dataset effectively
    df_iterator = pd.read_csv(path, header=header, chunksize=chunk_size)
    df = pd.concat(df_iterator)

    # check for duplicates and handle it appropriately if any is found
    if df.duplicated().sum() > 0:
        print(f"\nWarning: {df.duplicated().sum()} duplicates found")
        df.drop_duplicates(keep='first', inplace=True)
        print("Duplicates removed\n")

    # check if the number of column indexes provided is 1 or 2 else, raise Error
    column_count = len(column_ind)
    headers = df.columns
    if column_count > 2:
        raise ValueError(f"Number of column index provided should not exceed 2. {column_count} was provided")
    # if 2 column index provided, extract data of two columns
    elif column_count == 2:
        final_columns = column_extract(df, headers, column_ind, sum_col)
    # if 1 column index provided, extract data of column and create list of counts(1)
    elif column_count == 1:
        final_columns = column_extract(df, headers, column_ind, sum_col)
    else:
        raise ValueError(f"Minimum of 1 column index is expected. {column_count} was provided")
    return final_columns[0], final_columns[1], final_columns[2]


def column_extract(df, headers, column_ind, sum_col):
    """
    Extracts data from columns of a DataFrame based on provided column indices.

    Args:
        df (pd.DataFrame): DataFrame containing the data.
        headers (list): List of column names in the DataFrame.
        column_ind (list): List of column indices to be extracted.
        sum_col (int): Index of the column to be summed up by reducer.
    Returns:
        tuple: Tuple of extracted data for needed and column data
    Raises:
        KeyError: If any column index is not found in the DataFrame.
    """
    extracted_data = []
    for col_idx in column_ind:
        if col_idx >= len(headers):
            raise KeyError(f"Dataset has 0 to {len(headers) - 1} column indices. column_index provided : {col_idx}")
        extracted_data.append(df.iloc[:, col_idx].tolist())  # Extract column data to list

    # Get the column specified in sum_col
    if sum_col is False:
        counts = [1 for _ in range(len(df))]
    elif sum_col >= len(headers):
        raise KeyError(f"Dataset has 0 to {len(headers) - 1} column indices. sum_column provided : {sum_col}")
    else:
        counts = df.iloc[:, sum_col].tolist()

    return extracted_data[0], extracted_data[1], counts
