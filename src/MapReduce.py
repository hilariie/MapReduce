"""Functions for reading data and performing MapReduce to identify a word with the highest occurrence or count"""
import os
import re
import pandas as pd
from functools import reduce


class MapReduce:
    """MapReduce class for performing map and reduce operations on input data."""

    def __init__(self, pattern: list):
        """
        Initialize MapReduce object.

        Args:
            pattern (list): list of regular expression patterns used to check IDs
        """
        self.pattern = pattern

    def mapper1(self, id_: str, id_2: str) -> str:
        """
        Filters out rows with wrong flight IDs

        Args:
            id_: Passenger ID to be returned or not
            id_2: Flight ID to be checked if it matches given pattern

        Returns:
            str: Returns Passenger ID if Flight ID matches pattern, otherwise return empty string
        """
        id_2 = str(id_2)
        if re.findall(self.pattern[1], id_2):
            return id_
        else:
            return ''

    def mapper2(self, id_, count_=1) -> tuple:
        """
        Checks if passenger ID matches given pattern and returns a key-value pair

        Args:
            id_ (str): Passenger ID to be returned as key
            count_ (int): Second input to be returned as value. Default is 1.
        Returns:
            tuple: A tuple containing the passenger id and a count if passenger id matches pattern,
                   otherwise return a tuple of passenger id and None-type object
        """
        id_ = str(id_)
        try:
            int(count_)
        except ValueError:
            count_ = None
        except TypeError:
            count_ = None
        if re.findall(self.pattern[0], id_):
            return id_, count_
        else:
            return id_, None

    @staticmethod
    def shuffle(mapper_out: list) -> dict:
        """Joins the counts of each id in a list and store data as dict
        Args:
            mapper_out: List of key-value pairs generated by the mapper method.

        Returns:
            dict: A dictionary containing the organized key-value pairs.
        """
        data = {}
        # loop through key-value pair
        for id_, count_ in mapper_out:
            # check if count is int or a Nonetype object
            try:
                int(count_)
            except TypeError:
                continue  # Silently discard id which doesn't match pattern
            # if new id encountered, store id in dictionary as key and count as value
            # else append the count to the id being the key
            if id_ not in data:
                data[id_] = [count_]
            else:
                data[id_].append(count_)
        return data  # of shape -> {'id1': [1, 1, 1], 'id2': [1, 1]}

    @staticmethod
    def reduce_func(x: int, y: int) -> int:
        """Reduce function to process values for the same key.

        Args:
            x (int): First value to be reduced.
            y (int): Second value to be reduced.
        Returns:
            int: sum of provided integers
        """
        return x + y

    @staticmethod
    def final_output(reduce_out: dict) -> tuple:
        """
        Get the passenger id(s) with the highest number of flights.

        Args:
            reduce_out (dict): Dictionary of reduced key-value pairs.

        Returns:
            tuple: count and word pair for word(s) with the highest number of occurences or counts
        """
        # get maximum occurence of any word(ID) in dictionary
        max_count = max(reduce_out.values())
        # get all IDs with maximum occurence
        passengers = [pass_id for pass_id, value in list(reduce_out.items()) if value == max_count]
        # sort and convert list of IDs to formatted strings for pleasant display
        passengers = '\n\t '.join(sorted(passengers))
        return max_count, passengers

    def map_reduce_parallel(self, executor, args: list, test=False):
        """
        Performs map reduce on a list of data entries

        Args:
            executor: Executor to be used (ThreadPoolExecutor or ProcessPoolExecutor).
            args: List of 3 data entries in lists.
            test bool: Tells function not to display anything.

        Returns:
            word (str): word in first dataset with the highest occurrence or sum of count
            max_count (int): The highest occurrence or sum of count
        """
        with executor:
            # perform  mapping operations
            chunk_size = int(len(args[0])//executor._max_workers)
            # Perform mapping operations
            mapper_output1 = list(executor.map(self.mapper1, args[0], args[1], chunksize=chunk_size))
            mapper_output = list(executor.map(self.mapper2, mapper_output1, args[2], chunksize=chunk_size))
            self.display_log(test, 'Mapping successful')
            # perform shuffling operation
            reduce_input = executor.submit(self.shuffle, mapper_output).result()
            self.display_log(test, 'Shuffle succcessful')
            # Perform reducing operation and store value as dict
            reduce_output = {}
            for key, values in reduce_input.items():
                future = executor.submit(reduce, self.reduce_func, values)
                reduce_output[key] = future.result()
            # check if output is empty
            if reduce_output:
                self.display_log(test, 'Reduction succcessful')
            else:
                raise ValueError('Reduction Failed: output is empty')
            # perform final sorting
            max_count, word = self.final_output(reduce_output)
            self.display_log(test, 'Final sort Successful')
        return max_count, word

    @staticmethod
    def display_log(print_, str_):
        """
        Checks if it is appropriate, and displays output

        Args:
            print_ (bool): True if you wish to display output other False
            str_ (str): String to display
        """
        if not print_:
            print(str_)


def pretty_print(string1, string2=None, count_=7):
    """
    Print formatted strings with optional second string.
    Args:
        string1 (str): The first string to be printed.
        string2 (str, optional): The second string to be printed. Default is None.
        count_ (int, optional): The number of '-' characters for formatting. Default is 7.
    """
    print_style = '-' * count_
    if not string2:
        print(f"{print_style} {string1}:  {print_style}")
    else:
        print(f"{print_style} {string1}:  {print_style}\n\n{string2}")


def header_reader(header):
    """
    Checks if dataset has headers or not based on input

    Args:
        header: Indicator if dataset has headers or not

    Returns:
        returns 0 ('infer') if dataset has headers, otherwise None
    """
    if header:
        return 0
    else:
        return None


def read_data(path, column_ind, sum_col=False, header=None, chunk_size=1000) -> tuple:
    """
    Reads a CSV file and returns a tuple of needed column data.

    Args:
        path (str): Path to CSV file containing the data.
        sum_col (int): Index of column to be summed by reducer. Default is False.
        column_ind (list): list containing index of needed column(s) data.
        header (int): Indicates if csv file has headers or not. Defaults to None.
        chunk_size (int): Number of chunks to read csv file.

    Returns:
        tuple: Tuple of needed column data

    Raises:
        FileNotFoundError: If the CSV file does not exist.
        ValueError: If column_ind list has wrong length
    """
    # check if path exists otherwise throw error with efficient error message
    path_ext = os.path.splitext(path)
    if not os.path.exists(path):
        raise FileNotFoundError(f"Path to file not found: {path}")
    # check if file is a csv file
    elif path_ext[1] != '.csv':
        raise FileNotFoundError(f'Expected .csv file, got {path_ext[1]} instead')
    header = header_reader(header)
    df = pd.read_csv(path, header=header)

    # check for duplicates and handle it appropriately if any is found
    if df.duplicated().sum() > 0:
        print(f"\nWarning: {df.duplicated().sum()} duplicates found")
        df.drop_duplicates(keep='first', inplace=True)
        print("Duplicates removed\n")

    # check if the number of column indexes provided is 1 or 2 else, raise Error
    column_count = len(column_ind)
    headers = df.columns
    if column_count > 2:
        raise ValueError(f"Number of column index provided should not exceed 2. {column_count} was provided")
    # if 2 column index provided, extract data of two columns
    elif column_count == 2:
        final_columns = column_extract(df, headers, column_ind, sum_col)
    # if 1 column index provided, extract data of column and create list of counts(1)
    elif column_count == 1:
        final_columns = column_extract(df, headers, column_ind, sum_col)
    else:
        raise ValueError(f"Minimum of 1 column index is expected. {column_count} was provided")
    return final_columns[0], final_columns[1], final_columns[2]


def column_extract(df, headers, column_ind, sum_col):
    """
    Extracts data from columns of a DataFrame based on provided column indices.

    Args:
        df (pd.DataFrame): DataFrame containing the data.
        headers (list): List of column names in the DataFrame.
        column_ind (list): List of column indices to be extracted.
        sum_col (int): Index of the column to be summed up by reducer.
    Returns:
        tuple: Tuple of extracted data for needed and column data
    Raises:
        KeyError: If any column index is not found in the DataFrame.
    """
    extracted_data = []
    for col_idx in column_ind:
        if col_idx >= len(headers):
            raise KeyError(f"Dataset has 0 to {len(headers) - 1} column indices. column_index provided : {col_idx}")
        extracted_data.append(df.iloc[:, col_idx].tolist())  # Extract column data to list

    # Get the column specified in sum_col
    if sum_col is False:
        counts = [1 for _ in range(len(df))]
    elif sum_col >= len(headers):
        raise KeyError(f"Dataset has 0 to {len(headers) - 1} column indices. sum_column provided : {sum_col}")
    else:
        counts = df.iloc[:, sum_col].tolist()

    return extracted_data[0], extracted_data[1], counts
